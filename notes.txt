Maybe, title: Class Semantic Awareness for Visual Relationship Detection


Semantic dense representation instead of 1-hot.
Skip-Gram/CBOW


Makes sure that the model is still valid (validate original with original dataset)
Show the results with a randomly initialized untrained models.
  PRED TEST:
  	R@100:  70.558	ZS:  76.166
  	R@50:  37.993	ZS:  43.205
  ...

original, untrained
PRED TEST:
  R@100:  12.870  ZS:  13.858
  R@50:  2.907    ZS:  4.363


So we believe that the metrics are weak in this sense.

- Introduce a new metric (inspired from https://arxiv.org/pdf/2004.00436.pdf),
  consisting of a variation of R@50 and R@100 where the semantics of the predicates is taken into account.
  Some cosine distance-based metric.

- create the matrix manually?
	"on", "above", "on the top of",
	"next to", "beside", "near", "by", "adjacent to", "against",
	"in", "inside", "beneath",
	"under", "below",
	"contain", "outside of"
	"behind",
	"in the front of",
	"on the left of",
	"on the right of",
	"across"
	Then try to fuse these and create matrix manually?

- Then I thought, I can use this value to rescale all of the scores:
		if the value is high (it is likely that the pair is in a relationship),
		all of the scores for this object pair are going to be boosted,
		if the value is low (it is unlikely that the object pair is interacting in any way),
		they are going to be low.


 (this is what happens in works like \citebyaut{languagepriors} \citebyaut{structural-ranking} and
\citebyaut{prior-softmax}). % namely, the semantic embedding of the objects
% is computed using a pre-trained Word2Vec model, and a a different, independent,
% linear projection of the combined subject-object embeddings for every predicate.

 % consist of a 8-dimensional vector ... cite dsr

We're going to use R@50 and R@30 because the values were quite high already.
...To complete the description, their ranking approach involves all $n(n-1) \cdot M$ detections in an image to be ranked by score.
(at test time...)


DSR:
  One direct way to dealwith incomplete predicate annotation is to take the unla-
  beled relationships as negative samples and solve the rela
  tionship detection problem using a multi-label classification
  framework based on cross-entropy loss

  In this paper, we propose a deep neural network frame-work with structural ranking loss to tackle the visual rela-tionship detection problem

  Moreover, we integrate the structural losswith the probability of the predicates conditioned on its sub-
  ject and object to further reduce the impact of incompleteannotations

  MultiLabelMarginLoss: multi-label ranking loss

  Long-tail Classification (e.g read a little bit of https://arxiv.org/pdf/2004.00436.pdf)



New idea:
 look for "Letâ€™s build a proper (yet simple" here: https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e
 They have single parameters. Well, implement the linear projection for a predicate there. Beforee that, check if it's already there somewhere int he code.
 Do they claim it is already there, in the paper?

 To give example numbers, the model learns to give a 80% R@100 score without any input,
  and multi-modality only helps bringing it up to 93-95%. Also, it looks like one modality (vis, sem, spat)
  does most of the work, while the others do not help so much.
 Now, we implemented two ways of using the embeddings to improve the results,
  but we saw no improvement when used with all the modalities together.
  So right now we thought we could try introducing our predicate semantics ideas without using multi-modal features.
  For instance, with no input.
 But we would like an embedding model where antonyms have cosine similarity -1. Do you know where to find it?


https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)





Using a subset of 20 predicates, epoch 4
R@50  R@50 ZS     R@30     R@30 ZS    Avg.   Type
76.3011  62.2718  62.1933  45.9432  61.6774  no input
86.0595  73.2252  73.8662  57.5051  72.664   spat + prior
89.3494  79.1075  78.7546  63.0832  77.5737  spat (+ prior with lr 1e-4 & wd 1e-4 )
82.0632  69.4726  70.223   56.4909  69.5624  SemSim-1100 (+ prior with lr 1e-4 & wd 1e-4 )
76.4498  64.6045  67.974   54.8682  65.9741  SemSim-1100, 50-dim embeddings (+ prior with lr 1e-4 & wd 1e-4 )
89.3494  78.8032  79.052   62.8803  77.5213  Re-scoring-10001
89.0149  78.7018  79.3494  63.4888  77.6387  Re-scoring-10001, 50-dim
