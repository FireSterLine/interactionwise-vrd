One direct way to dealwith incomplete predicate annotation is to take the unla-
beled relationships as negative samples and solve the rela
tionship detection problem using a multi-label classification
framework based on cross-entropy loss

In this paper, we propose a deep neural network frame-work with structural ranking loss to tackle the visual rela-tionship detection problem

Moreover, we integrate the structural losswith the probability of the predicates conditioned on its sub-ject and object to further reduce the impact of incompleteannotations

The VGG16 comes from (Simonyanand Zisserman 2014)

MultiLabelMarginLoss: multi-label ranking loss

Long-tail Classification (e.g read a little bit of https://arxiv.org/pdf/2004.00436.pdf)



IDEAS:

Also try using MSE instead of cosine_similarity

Introduce a new metric (inspired from https://arxiv.org/pdf/2004.00436.pdf),
consisting of a variation of R@50 and R@100 where the semantics of the predicates is taken into account.
Some cosine distance-based metric.


https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/

New idea:
 look for "Letâ€™s build a proper (yet simple" here: https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e
 They have single parameters. Well, implement the linear projection for a predicate there. Beforee that, check if it's already there somewhere int he code.
 They claim it is, in the paper.



# TODO: use sampler in evaluation instead of subsampling with the index thing: torch.utils.data.Subset(dataset, indices)


cache datalayer output to file and load like with torch.load('data/' + ID + '.pt')


criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
